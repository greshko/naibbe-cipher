{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa363e8c-a3df-4dc6-9074-660ede241e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2025, Michael A. Greshko\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software, datasets, and associated documentation files (the \"Software\n",
    "# and Datasets\"), to deal in the Software and Datasets without restriction,\n",
    "# including without limitation the rights to use, copy, modify, merge, publish,\n",
    "# distribute, sublicense, and/or sell copies of the Software and Datasets, and to\n",
    "# permit persons to whom the Software is furnished to do so, subject to the\n",
    "# following conditions:\n",
    "# \n",
    "# - The above copyright notice and this permission notice shall be included\n",
    "#   in all copies or substantial portions of the Software and Datasets.\n",
    "# - Any publications making use of the Software and Datasets, or any substantial\n",
    "#   portions thereof, shall cite the Software and Datasets's original publication:\n",
    "# \n",
    "# > Greshko, Michael A. (2025). The Naibbe cipher: a substitution cipher that \n",
    "#   encrypts Latin and Italian as Voynich Manuscript-like ciphertext. Preprint;\n",
    "#   submitted to Cryptologia.\n",
    "#   \n",
    "# THE SOFTWARE AND DATASETS ARE PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    "# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO\n",
    "# EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR\n",
    "# OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "# THE SOFTWARE AND DATASETS.\n",
    "\n",
    "import random\n",
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# === Parameters ===\n",
    "ALPHABET = list(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "TABLES = ['alpha', 'beta1', 'beta2', 'beta3', 'gamma1', 'gamma2']\n",
    "STATES = ['unigram', 'prefix', 'suffix']\n",
    "# Use 18 for simplified respacing (50-50 unigram-bigram) and 17 for standard respacing (slight bigram excess)\n",
    "RESPACING = 17\n",
    "USE_78_CARD_DECK = True  # Toggle between 52-card and 78-card deck\n",
    "SPACE_REMOVAL_RATE = 0.03  # Fraction of spaces to randomly remove in \"respaced\" ciphertext output\n",
    "UNAMBIGUOUS = True         # Bigram generation avoids creating ambiguous tokens\n",
    "MAX_BIGRAM_RETRIES = 10000 # Safety fuse to prevent infinite loops\n",
    "\n",
    "# === Card weights ===\n",
    "CARD_WEIGHTS = {\n",
    "    False: {'alpha': 20, 'beta1': 8, 'beta2': 8, 'beta3': 8, 'gamma1': 4, 'gamma2': 4},\n",
    "    True:  {'alpha': 28, 'beta1': 14, 'beta2': 11, 'beta3': 11, 'gamma1': 7, 'gamma2': 7},\n",
    "}\n",
    "\n",
    "def generate_placeholder_tables():\n",
    "    table = defaultdict(dict)\n",
    "    for table_name in TABLES:\n",
    "        for state in STATES:\n",
    "            for letter in ALPHABET:\n",
    "                key = f\"{state}_{table_name}_{letter}\"\n",
    "                table[table_name][(state, letter)] = key\n",
    "    return table\n",
    "\n",
    "naibbe_tables = generate_placeholder_tables()\n",
    "\n",
    "# === Load glyph mappings from CSV ===\n",
    "glyph_df = pd.read_csv(\"references/naibbe_tables.csv\")  # Ensure this file is present\n",
    "placeholder_to_glyph = dict(zip(glyph_df['code'], glyph_df['glyphs']))\n",
    "\n",
    "# Precompute all unigram glyphs for ambiguity checking\n",
    "unigram_glyphs = {\n",
    "    glyph for code, glyph in placeholder_to_glyph.items()\n",
    "    if code.startswith(\"unigram_\")\n",
    "}\n",
    "\n",
    "# === Precompute all possible bigram concatenations to detect cross-bigram collisions ===\n",
    "def build_bigram_catalog(alphabet, tables, glyph_map):\n",
    "    \"\"\"\n",
    "    Returns dict: combined_str -> set of (prefix_code, suffix_code) pairs\n",
    "    A collision exists whenever len(set) > 1 for a combined_str,\n",
    "    i.e., multiple different (prefix, suffix) pairs map to the same string.\n",
    "    \"\"\"\n",
    "    bigram_catalog = defaultdict(set)\n",
    "\n",
    "    # Precompute prefix/suffix glyphs for all (table, letter)\n",
    "    prefix_map = {}\n",
    "    suffix_map = {}\n",
    "    for t in tables:\n",
    "        for L in alphabet:\n",
    "            p_code = f\"prefix_{t}_{L}\"\n",
    "            s_code = f\"suffix_{t}_{L}\"\n",
    "            p_g = glyph_map.get(p_code, p_code)\n",
    "            s_g = glyph_map.get(s_code, s_code)\n",
    "            prefix_map[(t, L)] = (p_code, p_g)\n",
    "            suffix_map[(t, L)] = (s_code, s_g)\n",
    "\n",
    "    # Enumerate all possible bigram word types (prefix any, suffix any)\n",
    "    for t1, L1 in prefix_map:\n",
    "        p_code, p_glyph = prefix_map[(t1, L1)]\n",
    "        for t2, L2 in suffix_map:\n",
    "            s_code, s_glyph = suffix_map[(t2, L2)]\n",
    "            combined = p_glyph + s_glyph\n",
    "            bigram_catalog[combined].add((p_code, s_code))\n",
    "\n",
    "    return bigram_catalog\n",
    "\n",
    "bigram_catalog = build_bigram_catalog(ALPHABET, TABLES, placeholder_to_glyph)\n",
    "\n",
    "# === Deck creation ===\n",
    "def create_card_deck(use_78=False):\n",
    "    weights = CARD_WEIGHTS[use_78]\n",
    "    deck = []\n",
    "    for table, count in weights.items():\n",
    "        deck.extend([table] * count)\n",
    "    random.shuffle(deck)\n",
    "    return deck\n",
    "\n",
    "# === Respacing ===\n",
    "def respace_plaintext(text, pre_plaintext_file=None):\n",
    "    text = text.lower().replace(\" \", \"\")\n",
    "    i = 0\n",
    "    output = []\n",
    "    while i < len(text):\n",
    "        if i == len(text) - 1 or random.random() < (RESPACING / 36):\n",
    "            output.append(text[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            output.append(text[i:i+2])\n",
    "            i += 2\n",
    "    # Write pre-encryption respaced plaintext to file if provided\n",
    "    if pre_plaintext_file is not None:\n",
    "        pre_plaintext_file.write(\" \".join(output) + \"\\n\")\n",
    "    return output\n",
    "\n",
    "# === Ambiguity log ===\n",
    "ambiguity_retries = 0\n",
    "\n",
    "# === Encryption ===\n",
    "def encrypt_naibbe(plaintext, tables, glyph_map, use_78=False, pre_plaintext_file=None):\n",
    "    global ambiguity_retries, bigram_catalog\n",
    "    ngrams = respace_plaintext(plaintext, pre_plaintext_file)\n",
    "    ciphertext = []\n",
    "    deck = create_card_deck(use_78)\n",
    "    deck_index = 0\n",
    "\n",
    "    for token in ngrams:\n",
    "        if len(token) == 1:\n",
    "            state = 'unigram'\n",
    "            letters = [token]\n",
    "        else:\n",
    "            state = 'bigram'\n",
    "            letters = [token[0], token[1]]\n",
    "\n",
    "        if state == 'unigram':\n",
    "            # === Unigram handling ===\n",
    "            if deck_index >= len(deck):\n",
    "                deck = create_card_deck(use_78)\n",
    "                deck_index = 0\n",
    "            table = deck[deck_index]\n",
    "            deck_index += 1\n",
    "            code = tables[table][('unigram', letters[0])]\n",
    "            glyph = glyph_map.get(code, code)\n",
    "            ciphertext.append(glyph)\n",
    "\n",
    "        else:  # state == 'bigram'\n",
    "            if UNAMBIGUOUS:\n",
    "                # === Ambiguity-safe bigram handling with unigram + cross-bigram collision checks ===\n",
    "                accepted = False\n",
    "                for _ in range(MAX_BIGRAM_RETRIES):\n",
    "                    # Prefix\n",
    "                    if deck_index >= len(deck):\n",
    "                        deck = create_card_deck(use_78)\n",
    "                        deck_index = 0\n",
    "                    table_prefix = deck[deck_index]\n",
    "                    deck_index += 1\n",
    "                    code_prefix = tables[table_prefix][('prefix', letters[0])]\n",
    "                    glyph_prefix = glyph_map.get(code_prefix, code_prefix)\n",
    "\n",
    "                    # Suffix\n",
    "                    if deck_index >= len(deck):\n",
    "                        deck = create_card_deck(use_78)\n",
    "                        deck_index = 0\n",
    "                    table_suffix = deck[deck_index]\n",
    "                    deck_index += 1\n",
    "                    code_suffix = tables[table_suffix][('suffix', letters[1])]\n",
    "                    glyph_suffix = glyph_map.get(code_suffix, code_suffix)\n",
    "\n",
    "                    combined = glyph_prefix + glyph_suffix\n",
    "\n",
    "                    # 1) reject if equals any unigram glyph\n",
    "                    if combined in unigram_glyphs:\n",
    "                        ambiguity_retries += 1\n",
    "                        continue\n",
    "\n",
    "                    # 2) reject if ANY OTHER possible (prefix,suffix) pair yields the same combined string\n",
    "                    pairs = bigram_catalog.get(combined, set())\n",
    "                    any_other = any(pair != (code_prefix, code_suffix) for pair in pairs)\n",
    "                    if any_other:\n",
    "                        ambiguity_retries += 1\n",
    "                        continue\n",
    "\n",
    "                    # Passed both checks → accept\n",
    "                    ciphertext.append(combined)\n",
    "                    accepted = True\n",
    "                    break\n",
    "\n",
    "                if not accepted:\n",
    "                    # Exhausted retries; emit the last attempt to avoid deadlock (or raise instead)\n",
    "                    ciphertext.append(glyph_prefix + glyph_suffix)\n",
    "            else:\n",
    "                # === Standard bigram handling (no collision checks) ===\n",
    "                first = True\n",
    "                for i, letter in enumerate(letters):\n",
    "                    if deck_index >= len(deck):\n",
    "                        deck = create_card_deck(use_78)\n",
    "                        deck_index = 0\n",
    "                    table = deck[deck_index]\n",
    "                    deck_index += 1\n",
    "                    substate = 'prefix' if i == 0 else 'suffix'\n",
    "                    code = tables[table][(substate, letter)]\n",
    "                    glyph = glyph_map.get(code, code)\n",
    "                    if first:\n",
    "                        ciphertext.append(glyph)\n",
    "                        first = False\n",
    "                    else:\n",
    "                        ciphertext[-1] += glyph\n",
    "\n",
    "    return ciphertext\n",
    "\n",
    "# === Full normalization of line with Latin replacement ===\n",
    "def clean_line(text):\n",
    "    normalized = unicodedata.normalize('NFD', text)\n",
    "    no_diacritics = ''.join(c for c in normalized if unicodedata.category(c) != 'Mn')\n",
    "    replacements = {\n",
    "        'æ': 'ae', 'Æ': 'ae',\n",
    "        'œ': 'oe', 'Œ': 'oe',\n",
    "        'ð': 'd',  'Ð': 'd',\n",
    "        'þ': 'th', 'Þ': 'th',\n",
    "        'ł': 'l',  'Ł': 'l',\n",
    "        'ß': 'ss',\n",
    "        'ø': 'o',  'Ø': 'o'\n",
    "    }\n",
    "    replaced = ''.join(replacements.get(c, c) for c in no_diacritics)\n",
    "    cleaned = ''.join(c for c in replaced if c.isalpha()).upper()\n",
    "    cleaned = cleaned.replace(\"W\", \"UU\").replace(\"J\", \"I\").replace(\"K\", \"C\")\n",
    "    return cleaned.lower()\n",
    "\n",
    "# === Randomly remove spaces in output ===\n",
    "def respace_line(line, drop_rate):\n",
    "    if drop_rate <= 0:\n",
    "        return line.strip()\n",
    "    if drop_rate >= 1:\n",
    "        return line.replace(\" \", \"\")\n",
    "\n",
    "    tokens = line.strip().split()\n",
    "    if len(tokens) < 2:\n",
    "        return line.strip()\n",
    "\n",
    "    output = tokens[0]\n",
    "    for tok in tokens[1:]:\n",
    "        if random.random() < drop_rate:\n",
    "            output += tok\n",
    "        else:\n",
    "            output += ' ' + tok\n",
    "    return output\n",
    "\n",
    "# === Line-by-line file encryption and optional respacing ===\n",
    "if __name__ == \"__main__\":\n",
    "    input_path = \"input/examples/nathist_book16.txt\"\n",
    "    output_path = \"encrypted/nathist_output_ciphertext_bigram_unambig.txt\"\n",
    "    respaced_output_path = \"encrypted/nathist_output_ciphertext_respaced_bigram_unambig.txt\"\n",
    "    pre_plaintext_output_path = \"respaced_plaintext/nathist_pre_encryption_respaced_plaintext_bigram_unambig.txt\"\n",
    "\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as fin, \\\n",
    "         open(output_path, \"w\", encoding=\"utf-8\") as fout, \\\n",
    "         open(respaced_output_path, \"w\", encoding=\"utf-8\") as frespace, \\\n",
    "         open(pre_plaintext_output_path, \"w\", encoding=\"utf-8\") as fplain:\n",
    "\n",
    "        for line in fin:\n",
    "            cleaned = clean_line(line)\n",
    "            if cleaned:\n",
    "                encrypted_tokens = encrypt_naibbe(\n",
    "                    cleaned, naibbe_tables, placeholder_to_glyph,\n",
    "                    use_78=USE_78_CARD_DECK,\n",
    "                    pre_plaintext_file=fplain\n",
    "                )\n",
    "                line_out = \" \".join(encrypted_tokens)\n",
    "                fout.write(line_out + \"\\n\")\n",
    "                frespace.write(respace_line(line_out, SPACE_REMOVAL_RATE) + \"\\n\")\n",
    "            else:\n",
    "                fout.write(\"\\n\")\n",
    "                frespace.write(\"\\n\")\n",
    "                fplain.write(\"\\n\")\n",
    "\n",
    "# === print ambiguity count ===\n",
    "if UNAMBIGUOUS:\n",
    "    print(f\"Total ambiguity retries: {ambiguity_retries}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
