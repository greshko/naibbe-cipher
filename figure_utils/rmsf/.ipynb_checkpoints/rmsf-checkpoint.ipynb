{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4eb6df8-6080-4919-9608-9e040cdbbfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2025, Michael A. Greshko\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software, datasets, and associated documentation files (the \"Software\n",
    "# and Datasets\"), to deal in the Software and Datasets without restriction,\n",
    "# including without limitation the rights to use, copy, modify, merge, publish,\n",
    "# distribute, sublicense, and/or sell copies of the Software and Datasets, and to\n",
    "# permit persons to whom the Software is furnished to do so, subject to the\n",
    "# following conditions:\n",
    "# \n",
    "# - The above copyright notice and this permission notice shall be included\n",
    "#   in all copies or substantial portions of the Software and Datasets.\n",
    "# - Any publications making use of the Software and Datasets, or any substantial\n",
    "#   portions thereof, shall cite the Software and Datasets's original publication:\n",
    "# \n",
    "# > Greshko, Michael A. (2025). The Naibbe cipher: a substitution cipher that encrypts\n",
    "# Latin and Italian as Voynich Manuscript-like ciphertext.\n",
    "# Cryptologia. https://doi.org/10.1080/01611194.2025.2566408\n",
    "#   \n",
    "# THE SOFTWARE AND DATASETS ARE PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    "# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO\n",
    "# EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR\n",
    "# OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "# THE SOFTWARE AND DATASETS.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import os\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# === Parameters ===\n",
    "CSV_PATH = \"data/reference_texts.csv\"\n",
    "PLOT_DIR = \"long_range_plots\"\n",
    "os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "MAX_BITS = 500_000\n",
    "window_sizes = np.unique(np.logspace(1.3, np.log10(MAX_BITS // 10), num=20, dtype=int))\n",
    "max_lag = 1000\n",
    "\n",
    "# === Helper Functions ===\n",
    "def text_to_binary(text):\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    text = ''.join(c for c in text if c.isalpha()).lower()\n",
    "    alpha = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    rank_map = {char: format(i + 1, '05b') for i, char in enumerate(alpha)}\n",
    "    return ''.join(rank_map.get(c, '') for c in text)\n",
    "\n",
    "def binary_to_walk(binary_str):\n",
    "    return np.cumsum([1 if bit == '1' else -1 for bit in binary_str])\n",
    "\n",
    "def compute_displacement(walk, l):\n",
    "    return walk[l:] - walk[:-l]\n",
    "\n",
    "def compute_rms_fluctuation_exact(walk, window_sizes):\n",
    "    N = len(walk)\n",
    "    F = []\n",
    "    for l in window_sizes:\n",
    "        if N - l <= 1:\n",
    "            F.append(0)\n",
    "            continue\n",
    "        dy = compute_displacement(walk, l)\n",
    "        var = np.mean(dy ** 2) - np.mean(dy) ** 2\n",
    "        F.append(np.sqrt(var))\n",
    "    return np.array(F)\n",
    "\n",
    "def compute_autocorrelation(bit_array, max_lag):\n",
    "    N = len(bit_array)\n",
    "    mean_val = np.mean(bit_array)\n",
    "    C = []\n",
    "    for l in range(1, max_lag + 1):\n",
    "        cov = np.mean(bit_array[l:] * bit_array[:-l]) - mean_val ** 2\n",
    "        C.append(cov)\n",
    "    C = np.array(C)\n",
    "    C_cum = np.cumsum(C) / np.arange(1, max_lag + 1)\n",
    "    return C, C_cum\n",
    "\n",
    "def analyze_shuffled_text(binary):\n",
    "    shuffled = list(binary)\n",
    "    np.random.shuffle(shuffled)\n",
    "    shuffled_binary = ''.join(shuffled)\n",
    "    bit_array = np.array([int(b) for b in shuffled_binary])\n",
    "    walk = binary_to_walk(shuffled_binary)\n",
    "    F_n = compute_rms_fluctuation_exact(walk, window_sizes)\n",
    "    log_n = np.log10(window_sizes)\n",
    "    log_F = np.log10(F_n)\n",
    "    slope, _, _, _, _ = linregress(log_n, log_F)\n",
    "    diffs = np.diff(log_F / log_n)\n",
    "    crossover_index = np.argmax(diffs)\n",
    "    crossover_n = window_sizes[crossover_index] if crossover_index < len(window_sizes) else None\n",
    "    return round(slope, 3), crossover_n\n",
    "\n",
    "# === Load CSV ===\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "results = []\n",
    "\n",
    "# === Analyze Each Column ===\n",
    "for col in df.columns:\n",
    "    words = df[col].dropna().astype(str)\n",
    "    binary = ''.join(text_to_binary(''.join(words)))[:MAX_BITS]\n",
    "    bit_array = np.array([int(b) for b in binary])\n",
    "    walk = binary_to_walk(binary)\n",
    "\n",
    "    # Exact RMSF\n",
    "    F_n = compute_rms_fluctuation_exact(walk, window_sizes)\n",
    "    log_n = np.log10(window_sizes)\n",
    "    log_F = np.log10(F_n)\n",
    "    slope, _, _, _, _ = linregress(log_n, log_F)\n",
    "    hurst = round(slope, 3)\n",
    "\n",
    "    # Crossover point\n",
    "    diffs = np.diff(log_F / log_n)\n",
    "    crossover_index = np.argmax(diffs)\n",
    "    crossover_n = window_sizes[crossover_index] if crossover_index < len(window_sizes) else None\n",
    "\n",
    "    # Autocorrelation\n",
    "    C, C_cum = compute_autocorrelation(bit_array, max_lag)\n",
    "\n",
    "    # Plot RMSF\n",
    "    plt.figure()\n",
    "    plt.plot(log_n, log_F, 'o-', label=f\"H ≈ {hurst}\")\n",
    "    ref_line = log_F[0] + 0.5 * (log_n - log_n[0])\n",
    "    plt.plot(log_n, ref_line, 'k--', label='Reference slope = 0.5')\n",
    "    if crossover_n:\n",
    "        plt.axvline(np.log10(crossover_n), color='red', linestyle='--', label=f'Crossover ≈ {crossover_n}')\n",
    "    plt.xlabel(\"log10(n)\")\n",
    "    plt.ylabel(\"log10(F(n))\")\n",
    "    plt.title(f\"RMS Fluctuation (Exact) for '{col}'\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    rmsf_path = os.path.join(PLOT_DIR, f\"{col}_rmsf_exact.png\")\n",
    "    plt.savefig(rmsf_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Save RMSF data as CSV\n",
    "    rmsf_data = pd.DataFrame({\"window_size\": window_sizes, \"rmsf\": F_n})\n",
    "    rmsf_data.to_csv(os.path.join(PLOT_DIR, f\"{col}_rmsf_data.csv\"), index=False)\n",
    "\n",
    "    # Plot autocorrelation\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, max_lag + 1), C_cum, label=\"Cumulative Autocorrelation\")\n",
    "    plt.xlabel(\"Lag ℓ\")\n",
    "    plt.ylabel(\"C_c(ℓ)\")\n",
    "    plt.title(f\"Cumulative Step Autocorrelation for '{col}'\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    autocorr_path = os.path.join(PLOT_DIR, f\"{col}_autocorrelation.png\")\n",
    "    plt.savefig(autocorr_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Shuffled version\n",
    "    shuffled_hurst, shuffled_crossover = analyze_shuffled_text(binary)\n",
    "\n",
    "    results.append({\n",
    "        \"Text\": col,\n",
    "        \"Hurst Exponent\": hurst,\n",
    "        \"Crossover Point\": crossover_n,\n",
    "        \"Shuffled Hurst Exponent\": shuffled_hurst,\n",
    "        \"Shuffled Crossover Point\": shuffled_crossover,\n",
    "        \"RMSF Plot Path\": rmsf_path,\n",
    "        \"Autocorrelation Plot Path\": autocorr_path\n",
    "    })\n",
    "\n",
    "# === Save Summary ===\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df.to_csv(\"long_range_correlation_results.csv\", index=False)\n",
    "\n",
    "# === Comparison Chart ===\n",
    "x = summary_df[\"Text\"]\n",
    "x_indices = np.arange(len(x))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(x_indices - width/2, summary_df[\"Hurst Exponent\"], width, label=\"Original\")\n",
    "plt.bar(x_indices + width/2, summary_df[\"Shuffled Hurst Exponent\"], width, label=\"Shuffled\")\n",
    "plt.xticks(x_indices, x)\n",
    "plt.title(\"Hurst Exponent Comparison\")\n",
    "plt.ylabel(\"α\")\n",
    "plt.ylim(0.4, 0.75)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(x_indices - width/2, summary_df[\"Crossover Point\"], width, label=\"Original\")\n",
    "plt.bar(x_indices + width/2, summary_df[\"Shuffled Crossover Point\"], width, label=\"Shuffled\")\n",
    "plt.xticks(x_indices, x)\n",
    "plt.title(\"Crossover Point Comparison\")\n",
    "plt.ylabel(\"nₓ\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"comparison_chart_with_shuffled.png\"))\n",
    "plt.close()\n",
    "\n",
    "# === All RMSF Curves on One Plot ===\n",
    "plt.figure(figsize=(8, 6))\n",
    "for col in df.columns:\n",
    "    words = df[col].dropna().astype(str)\n",
    "    binary = ''.join(text_to_binary(''.join(words)))[:MAX_BITS]\n",
    "    walk = binary_to_walk(binary)\n",
    "    F_n = compute_rms_fluctuation_exact(walk, window_sizes)\n",
    "    log_n = np.log10(window_sizes)\n",
    "    log_F = np.log10(F_n)\n",
    "    plt.plot(log_n, log_F, label=f\"{col}\")\n",
    "plt.plot(log_n, log_F[0] + 0.5 * (log_n - log_n[0]), 'k--', label='Reference slope = 0.5')\n",
    "plt.xlabel(\"log10(n)\")\n",
    "plt.ylabel(\"log10(F(n))\")\n",
    "plt.title(\"RMS Fluctuation Curves Across Texts\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"all_texts_rmsf_curves.png\"))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd0c3e-3b4d-4ade-bcf6-83a388e23e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
